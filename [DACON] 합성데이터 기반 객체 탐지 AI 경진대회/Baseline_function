{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMJBWIUqHhIIt4bxjNgRxpg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"WG0Fi92TBAAN"},"outputs":[],"source":["import random\n","import pandas as pd\n","import numpy as np\n","import os\n","import glob\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","import torchvision\n","import torchvision.models as models\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor, FasterRCNN\n","from torchvision.models.detection.rpn import AnchorGenerator\n","from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n","\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensorV2\n","from tqdm.auto import tqdm"]},{"cell_type":"code","source":["def draw_boxes_on_image(image_path, annotation_path):\n","    # 이미지 불러오기\n","    image = cv2.imread(image_path)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # txt 파일에서 Class ID와 Bounding Box 정보 읽기\n","    with open(annotation_path, 'r') as file:\n","        lines = file.readlines()\n","\n","    for line in lines:\n","        values = list(map(float, line.strip().split(' ')))\n","        class_id = int(values[0])\n","        x_min, y_min = int(round(values[1])), int(round(values[2]))\n","        x_max, y_max = int(round(max(values[3], values[5], values[7]))), int(round(max(values[4], values[6], values[8])))\n","\n","        # 이미지에 바운딩 박스 그리기\n","        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)\n","        cv2.putText(image, str(class_id), (x_min, y_min - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n","\n","    # 이미지와 바운딩 박스 출력\n","    plt.figure(figsize=(25, 25))\n","    plt.imshow(image)\n","    plt.show()"],"metadata":{"id":"BYMpxQPVBLzb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def collate_fn(batch):\n","    images, targets_boxes, targets_labels = tuple(zip(*batch))\n","    images = torch.stack(images, 0)\n","    targets = []\n","    \n","    for i in range(len(targets_boxes)):\n","        target = {\n","            \"boxes\": targets_boxes[i],\n","            \"labels\": targets_labels[i]\n","        }\n","        targets.append(target)\n","\n","    return images, targets\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, root, train=True, transforms=None):\n","        self.root = root\n","        self.train = train\n","        self.transforms = transforms\n","        self.imgs = sorted(glob.glob(root+'/*.png'))\n","        \n","        if train:\n","            self.boxes = sorted(glob.glob(root+'/*.txt'))\n","\n","    def parse_boxes(self, box_path):\n","        with open(box_path, 'r') as file:\n","            lines = file.readlines()\n","\n","        boxes = []\n","        labels = []\n","\n","        for line in lines:\n","            values = list(map(float, line.strip().split(' ')))\n","            class_id = int(values[0])\n","            x_min, y_min = int(round(values[1])), int(round(values[2]))\n","            x_max, y_max = int(round(max(values[3], values[5], values[7]))), int(round(max(values[4], values[6], values[8])))\n","\n","            boxes.append([x_min, y_min, x_max, y_max])\n","            labels.append(class_id)\n","\n","        return torch.tensor(boxes, dtype=torch.float32), torch.tensor(labels, dtype=torch.int64)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.imgs[idx]\n","        img = cv2.imread(self.imgs[idx])\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n","        img /= 255.0\n","        height, width = img.shape[0], img.shape[1]\n","\n","        if self.train:\n","            box_path = self.boxes[idx]\n","            boxes, labels = self.parse_boxes(box_path)\n","            labels += 1 # Background = 0\n","\n","            if self.transforms is not None:\n","                transformed = self.transforms(image=img, bboxes=boxes, labels=labels)\n","                img, boxes, labels = transformed[\"image\"], transformed[\"bboxes\"], transformed[\"labels\"]\n","                \n","            return img, torch.tensor(boxes, dtype=torch.float32), torch.tensor(labels, dtype=torch.int64)\n","\n","        else:\n","            if self.transforms is not None:\n","                transformed = self.transforms(image=img)\n","                img = transformed[\"image\"]\n","            file_name = img_path.split('/')[-1]\n","            return file_name, img, width, height\n","\n","    def __len__(self):\n","        return len(self.imgs)\n","        \n","def get_train_transforms():\n","    return A.Compose([\n","        A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n","        ToTensorV2(),\n","    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n","\n","def get_test_transforms():\n","    return A.Compose([\n","        A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n","        ToTensorV2(),\n","    ])"],"metadata":{"id":"dS6fJBTDBN_7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_model(num_classes=CFG['NUM_CLASS']+1):\n","    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","    in_features = model.roi_heads.box_predictor.cls_score.in_features\n","    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n","    return model\n","\n","def train(model, train_loader, optimizer, scheduler, device):\n","    model.to(device)\n","\n","    best_loss = 9999999\n","    best_model = None\n","    \n","    for epoch in range(1, CFG['EPOCHS']+1):\n","        model.train()\n","        train_loss = []\n","        for images, targets in tqdm(iter(train_loader)):\n","            images = [img.to(device) for img in images]\n","            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","            \n","            optimizer.zero_grad()\n","\n","            loss_dict = model(images, targets)\n","            losses = sum(loss for loss in loss_dict.values())\n","\n","            losses.backward()\n","            optimizer.step()\n","\n","            train_loss.append(losses.item())\n","\n","        if scheduler is not None:\n","            scheduler.step()\n","        \n","        tr_loss = np.mean(train_loss)\n","\n","        print(f'Epoch [{epoch}] Train loss : [{tr_loss:.5f}]\\n')\n","        \n","        if best_loss > tr_loss:\n","            best_loss = tr_loss\n","            best_model = model\n","    \n","    return best_model"],"metadata":{"id":"vDmCJYyQBQIn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def box_denormalize(x1, y1, x2, y2, width, height):\n","    x1 = (x1 / CFG['IMG_SIZE']) * width\n","    y1 = (y1 / CFG['IMG_SIZE']) * height\n","    x2 = (x2 / CFG['IMG_SIZE']) * width\n","    y2 = (y2 / CFG['IMG_SIZE']) * height\n","    return x1.item(), y1.item(), x2.item(), y2.item()\n","\n","def inference(model, test_loader, device):\n","    model.eval()\n","    model.to(device)\n","    \n","    results = pd.read_csv('./sample_submission.csv')\n","\n","    for img_files, images, img_width, img_height in tqdm(iter(test_loader)):\n","        images = [img.to(device) for img in images]\n","\n","        with torch.no_grad():\n","            outputs = model(images)\n","\n","        for idx, output in enumerate(outputs):\n","            boxes = output[\"boxes\"].cpu().numpy()\n","            labels = output[\"labels\"].cpu().numpy()\n","            scores = output[\"scores\"].cpu().numpy()\n","\n","            for box, label, score in zip(boxes, labels, scores):\n","                x1, y1, x2, y2 = box\n","                x1, y1, x2, y2 = box_denormalize(x1, y1, x2, y2, img_width[idx], img_height[idx])\n","                results = results.append({\n","                    \"file_name\": img_files[idx],\n","                    \"class_id\": label-1,\n","                    \"confidence\": score,\n","                    \"point1_x\": x1, \"point1_y\": y1,\n","                    \"point2_x\": x2, \"point2_y\": y1,\n","                    \"point3_x\": x2, \"point3_y\": y2,\n","                    \"point4_x\": x1, \"point4_y\": y2\n","                }, ignore_index=True)\n","\n","    # 결과를 CSV 파일로 저장\n","    results.to_csv('./baseline_submit.csv', index=False)\n","    print('Done.')"],"metadata":{"id":"-ELurIp2BbIq"},"execution_count":null,"outputs":[]}]}