{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, SGD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sm_name</th>\n",
       "      <th>#</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>+</th>\n",
       "      <th>-</th>\n",
       "      <th>/</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>S</th>\n",
       "      <th>[</th>\n",
       "      <th>\\</th>\n",
       "      <th>]</th>\n",
       "      <th>c</th>\n",
       "      <th>l</th>\n",
       "      <th>n</th>\n",
       "      <th>o</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clotrimazole</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mometasone Furoate</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Idelalisib</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vandetanib</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bosutinib</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>CGM-097</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>TGX 221</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Azacitidine</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Atorvastatin</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Riociguat</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                sm_name  #   (   )  +  -  /  1  2  3  ...  S  [  \\  ]   c  l  \\\n",
       "0          Clotrimazole  0   2   2  0  0  0  8  0  0  ...  0  0  0  0  21  1   \n",
       "1    Mometasone Furoate  0   8   8  0  0  0  4  2  2  ...  0  8  0  8   4  2   \n",
       "2            Idelalisib  0   3   3  0  1  0  6  4  0  ...  0  2  0  2  19  0   \n",
       "3            Vandetanib  0   3   3  0  0  0  4  2  2  ...  0  0  0  0  14  0   \n",
       "4             Bosutinib  1   6   6  0  0  0  2  2  2  ...  0  0  0  0  15  2   \n",
       "..                  ... ..  ..  .. .. .. .. .. .. ..  ... .. .. .. ..  .. ..   \n",
       "141             CGM-097  0  11  11  0  0  0  6  2  2  ...  0  3  0  3  18  1   \n",
       "142             TGX 221  0   4   4  0  0  0  2  4  2  ...  0  0  0  0  14  0   \n",
       "143         Azacitidine  0   4   4  0  0  0  2  2  0  ...  0  4  0  4   3  0   \n",
       "144        Atorvastatin  0   9   9  0  2  0  2  6  0  ...  0  2  0  2  22  0   \n",
       "145           Riociguat  0   5   5  0  1  0  2  2  4  ...  0  0  0  0  16  0   \n",
       "\n",
       "     n  o  r  s  \n",
       "0    2  0  0  0  \n",
       "1    0  1  0  0  \n",
       "2    6  0  0  0  \n",
       "3    2  0  1  0  \n",
       "4    1  0  0  0  \n",
       "..  .. .. .. ..  \n",
       "141  0  0  0  0  \n",
       "142  2  0  0  0  \n",
       "143  3  0  0  0  \n",
       "144  1  0  0  0  \n",
       "145  5  0  0  0  \n",
       "\n",
       "[146 rows x 33 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_smile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature select\n",
    "# feature는 cell_type, sm_name, mean value, SMILES 이용, \n",
    "# 최대한 id_map에 맞게 최소한으로 설정할건데 일단은 de_train을 기준으로 해보자\n",
    "\n",
    "de_train = pd.read_parquet(\"/home/aiuser/taeuk/open-problems-single-cell-perturbations/de_train.parquet\")\n",
    "id_map = pd.read_csv(\"/home/aiuser/taeuk/open-problems-single-cell-perturbations/id_map.csv\")\n",
    "submission = pd.read_csv(\"/home/aiuser/taeuk/open-problems-single-cell-perturbations/sample_submission.csv\")\n",
    "\n",
    "sm_name_id_map = sorted(id_map.sm_name.unique())\n",
    "cell_type_id_map = sorted(id_map.cell_type.unique())\n",
    "\n",
    "# cell & compound dictionary\n",
    "\n",
    "cell_type_de_train = sorted(de_train.cell_type.unique())\n",
    "sm_name_de_train = sorted(de_train.sm_name.unique())\n",
    "\n",
    "cell_type_dict = {cell_type_de_train[i]:i for i in range(len(cell_type_de_train))}\n",
    "sm_name_dict = {sm_name_de_train[i]:i for i in range(len(sm_name_de_train))}\n",
    "\n",
    "# compound info by SMILES\n",
    "\n",
    "smiles = list(de_train.SMILES.unique())\n",
    "voc = []\n",
    "\n",
    "r = re.compile(\".\")\n",
    "for sm in smiles:\n",
    "    voc += list(set(r.findall(sm)))\n",
    "voc = list(set(voc))\n",
    "voc.sort()\n",
    "\n",
    "df_smile = pd.DataFrame(np.zeros((len(smiles), len(voc))).astype(int))\n",
    "df_smile.columns = voc\n",
    "for i in range(df_smile.shape[0]):\n",
    "    for ele in r.findall(smiles[i]):\n",
    "        df_smile[ele][i] += 1\n",
    "df_smile = pd.DataFrame(smiles).join(df_smile)\n",
    "df_smile.columns = [\"SMILES\"] + list(df_smile.columns[1:])\n",
    "sm_id = de_train.iloc[:, 1:4].drop(\"sm_lincs_id\", axis=1).drop_duplicates()\n",
    "df_smile = sm_id.merge(df_smile, how=\"left\", on=\"SMILES\")\n",
    "df_smile.drop(\"SMILES\", axis=1, inplace=True)\n",
    "\n",
    "# build dataloader\n",
    "\n",
    "class SCPset(Dataset):\n",
    "    def __init__(self, dataset, df_smile, cell_type_dict, sm_name_dict):\n",
    "        super(SCPset, self).__init__()\n",
    "        if dataset is None:\n",
    "            self.x = id_map.iloc[:, 1:]\n",
    "            self.y = None\n",
    "        else:\n",
    "            self.x = dataset.iloc[:, :2]\n",
    "            self.y = dataset.iloc[:, 5:]\n",
    "        self.smile = df_smile\n",
    "        self.cell_type_dict = cell_type_dict\n",
    "        self.sm_name_dict = sm_name_dict\n",
    "   \n",
    "    def __getitem__(self, idx):\n",
    "        cell, name = self.x.iloc[idx]\n",
    "        x_cell = self.cell_type_dict[cell]\n",
    "        x_comp = self.smile.loc[self.smile.sm_name==name, \"#\":].values[0]\n",
    "        ele_idx = np.where(x_comp!=0)[0][1:]\n",
    "        ele_val = x_comp[ele_idx]\n",
    "        ele_idx = list(ele_idx) + [0]*(20-len(ele_idx))\n",
    "        ele_val = list(ele_val) + [0]*(20-len(ele_val))\n",
    "        x = [x_cell] + list(ele_idx) + list(ele_val)\n",
    "        if self.y is None:\n",
    "            return torch.tensor(x, dtype=torch.int64)\n",
    "        else:\n",
    "            y = self.y.iloc[idx, :]\n",
    "            return torch.tensor(x, dtype=torch.int64),\\\n",
    "                    torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "'''\n",
    "input : [cell, comp, smil]\n",
    "x     : tensor size of (B, dim_embed)      \n",
    "'''\n",
    "class SCPblock(nn.Module):\n",
    "    def __init__(self, dim_embed, device):\n",
    "        super(SCPblock, self).__init__()\n",
    "        self.fc1 = nn.Linear(dim_embed, dim_embed, device=device)\n",
    "        self.fc2 = nn.Linear(dim_embed, dim_embed, device=device)\n",
    "        self.elu = nn.ELU()\n",
    "        \n",
    "    def forward(self ,x):\n",
    "        x_ = self.elu(self.fc1(x))\n",
    "        return self.elu(self.fc2(x_)+x)\n",
    "        \n",
    "class SCPmodel(nn.Module):\n",
    "    def __init__(self, dim_embed, num_layers, num_adds, gene, device):\n",
    "        super(SCPmodel, self).__init__()\n",
    "        self.embed_cell = nn.Embedding(6, dim_embed, device=device)\n",
    "        self.embed_comp = nn.Embedding(33, dim_embed*2, padding_idx=0, device=device)\n",
    "        self.embed_gene = torch.randn(size=(1, gene, dim_embed*3),\n",
    "                                      device=device, requires_grad=True)\n",
    "        self.num_adds = num_adds\n",
    "        self.layers = nn.ModuleList([\n",
    "            SCPblock(dim_embed*3, device) for _ in range(num_layers) ])\n",
    "            \n",
    "    def forward(self, x):\n",
    "        cell = self.embed_cell(x[:, 0]).unsqueeze(1)\n",
    "        comp_idx = x[:, 1:21]\n",
    "        comp_val = x[:, 21:]\n",
    "        comp = self.embed_comp(comp_idx)\n",
    "        comp = comp * comp_val.unsqueeze(2)\n",
    "        comp = comp.mean(dim=1, keepdim=True)\n",
    "        x = torch.cat([cell, comp], dim=2)\n",
    "        x = x.expand(cell.shape[0], self.embed_gene.shape[1], cell.shape[2]*3)\n",
    "        x = x + self.embed_gene\n",
    "        for i in range(len(self.layers)):\n",
    "            x = self.layers[i](x)\n",
    "            # # add gene embedding\n",
    "            # if i % (len(self.layers) // self.num_adds)==0:\n",
    "            #     x = x + self.embed_gene\n",
    "        return x.mean(dim=2, keepdim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define util function\n",
    "\n",
    "def MRRMSE(pred, y):\n",
    "      pred = pred.detach().cpu().numpy()\n",
    "      y = y.detach().cpu().numpy()\n",
    "      return np.sqrt(np.square(y - pred).mean(axis=1)).mean()    \n",
    "\n",
    "def mrrmse_loss(pred, y):\n",
    "      return torch.sqrt(torch.square(pred - y).mean(dim=1)).mean()\n",
    "\n",
    "def compose_loss(pred, y):\n",
    "      return mrrmse_loss(pred, y) + F.smooth_l1_loss(pred, y)\n",
    "\n",
    "def fix_random_seed(seed):\n",
    "    #random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training function\n",
    "\n",
    "def train_model(device, train_size, dim_model, num_layers, num_adds, genes, optimizer, criterion, learning_rate, num_epochs, batch_size, verbose):\n",
    "      \n",
    "      train_idx = np.random.choice(de_train.shape[0], int(de_train.shape[0]*train_size), replace=False)\n",
    "      train_loader = DataLoader(SCPset(de_train.iloc[train_idx, :], df_smile, cell_type_dict, sm_name_dict),\n",
    "                                batch_size=batch_size, shuffle=True)\n",
    "      valid_loader = [1]\n",
    "      if train_size < 1.:\n",
    "            valid_idx = list(set(np.arange(de_train.shape[0])) - set(train_idx))\n",
    "            valid_loader = DataLoader(SCPset(de_train.iloc[valid_idx, :], df_smile, cell_type_dict, sm_name_dict),\n",
    "                                      batch_size=batch_size, shuffle=True)\n",
    "\n",
    "      model = SCPmodel(dim_model, num_layers, num_adds, genes, device)\n",
    "      \n",
    "      if optimizer.lower()==\"sgd\":\n",
    "            optimizer = SGD(list(model.parameters())+[model.embed_gene], lr=learning_rate, momentum=0.)\n",
    "      elif optimizer.lower()=='adam':\n",
    "            optimizer = Adam(list(model.parameters())+[model.embed_gene], lr=learning_rate)\n",
    "      else:\n",
    "            print(\"Wrong optimizer!\")\n",
    "            return\n",
    "      \n",
    "      scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)\n",
    "      \n",
    "      if criterion.lower()==\"l1\":\n",
    "            criterion = nn.SmoothL1Loss(0.5)\n",
    "      elif criterion.lower()==\"l2\":\n",
    "            criterion = nn.MSELoss()\n",
    "      elif criterion.lower()==\"MRRMSE\":\n",
    "            criterion = mrrmse_loss\n",
    "      elif criterion.lower() == \"compose\":\n",
    "            criterion = compose_loss\n",
    "      else:\n",
    "            print(\"Wrong criterion!\")\n",
    "            return\n",
    "      \n",
    "      best_mrrmse = 10\n",
    "      for epoch in tqdm(range(1, num_epochs+1)):\n",
    "            train_loss = 0.\n",
    "            valid_loss = 0.\n",
    "            train_mrrmse = 0.\n",
    "            valid_mrrmse = 0.\n",
    "            \n",
    "            model.train()\n",
    "            for x, y in train_loader:\n",
    "                  x, y = x.to(device), y.to(device)\n",
    "                  optimizer.zero_grad()\n",
    "                  pred = model(x)\n",
    "                  if F.mse_loss(pred[0,:], pred[1,:]).item() < 0.0001:\n",
    "                        print(\"trivial solution !, mse of prediction is %.6f\"%F.mse_loss(pred[0,:], pred[1,:]).item())\n",
    "                  loss = criterion(pred, y)\n",
    "                  model.embed_gene.retain_grad()\n",
    "                  loss.backward()\n",
    "                  optimizer.step()\n",
    "                  \n",
    "                  train_loss += loss.item()\n",
    "                  train_mrrmse += MRRMSE(pred, y)\n",
    "            if train_size < 1.:\n",
    "                  model.eval()\n",
    "                  for x, y in valid_loader:\n",
    "                        x, y = x.to(device), y.to(device)\n",
    "                        with torch.no_grad():\n",
    "                              pred = model(x)\n",
    "                              loss = criterion(pred, y)\n",
    "                        \n",
    "                        valid_loss += loss.item()\n",
    "                        valid_mrrmse += MRRMSE(pred, y)\n",
    "            scheduler.step()      \n",
    "            # print loss per epoch\n",
    "            if verbose:\n",
    "                  print(\"[Epoch : %2d] [Loss : %.4f / %.4f] [MRRMSE : %.3f / %.3f]\"%(\n",
    "                        epoch, train_loss/len(train_loader), valid_loss/len(valid_loader),\n",
    "                        train_mrrmse/len(train_loader), valid_mrrmse/len(valid_loader)))\n",
    "            if train_size < 1. and best_mrrmse > valid_mrrmse/len(valid_loader):\n",
    "                  best_mrrmse = valid_mrrmse/len(valid_loader)\n",
    "            \n",
    "      return model, best_mrrmse\n",
    "\n",
    "def infer_model(device, model):\n",
    "      test_loader = DataLoader(SCPset(None, df_smile, cell_type_dict, sm_name_dict),\n",
    "                               batch_size=255, shuffle=False)\n",
    "      model.eval()\n",
    "      for x in test_loader:\n",
    "            x = x.to(device)\n",
    "            with torch.no_grad():\n",
    "                  pred = model(x)\n",
    "      return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameter tuning\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# result = []\n",
    "# fix_random_seed(231111)\n",
    "# train_size = 0.7\n",
    "# num_epochs = 10\n",
    "# for dim_model in [16]:\n",
    "#     for num_layers in [14]:\n",
    "#         for learning_rate in [0.05]:\n",
    "#             for batch_size in [64]:\n",
    "#                 model, mrrmse = train_model(device, train_size, dim_model, num_layers, 18211,\n",
    "#                                         \"Adam\", \"L1\", learning_rate, num_epochs, batch_size, True)\n",
    "#                 res = [dim_model, num_layers, learning_rate, batch_size, mrrmse]\n",
    "#                 result.append(res)\n",
    "# result = np.array(result)\n",
    "# result\n",
    "\n",
    "# gene_info = model.embed_gene.data.squeeze().cpu().numpy()\n",
    "# gene_info = pd.DataFrame(gene_info)\n",
    "# display(gene_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiuser/.conda/envs/taeuk/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca65a1cd0cd54903871a443ae2e8202c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1876720/2686368559.py:72: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  torch.tensor(y, dtype=torch.float32)\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 7.82 GiB. GPU 0 has a total capacty of 23.64 GiB of which 7.73 GiB is free. Including non-PyTorch memory, this process has 15.90 GiB memory in use. Of the allocated memory 15.70 GiB is allocated by PyTorch, and 9.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/aiuser/taeuk/scp_model.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/scp_model.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m \u001b[39m# 10 으로 했을때 0.65\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/scp_model.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m fix_random_seed(\u001b[39m231111\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/scp_model.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m model, mrrmse \u001b[39m=\u001b[39m train_model(device, train_size, dim_model, num_layers, num_adds,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/scp_model.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m                             \u001b[39m18211\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mAdam\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mL1\u001b[39;49m\u001b[39m\"\u001b[39;49m, learning_rate, num_epochs, batch_size, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/scp_model.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m pred \u001b[39m=\u001b[39m infer_model(device, model)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/scp_model.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m data \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n",
      "\u001b[1;32m/home/aiuser/taeuk/scp_model.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/scp_model.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m x, y \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/scp_model.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/scp_model.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m pred \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/scp_model.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mif\u001b[39;00m F\u001b[39m.\u001b[39mmse_loss(pred[\u001b[39m0\u001b[39m,:], pred[\u001b[39m1\u001b[39m,:])\u001b[39m.\u001b[39mitem() \u001b[39m<\u001b[39m \u001b[39m0.0001\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/scp_model.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m       \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtrivial solution !, mse of prediction is \u001b[39m\u001b[39m%.6f\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39mF\u001b[39m.\u001b[39mmse_loss(pred[\u001b[39m0\u001b[39m,:], pred[\u001b[39m1\u001b[39m,:])\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/.conda/envs/taeuk/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/taeuk/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/aiuser/taeuk/scp_model.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/scp_model.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_gene\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/scp_model.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers)):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/scp_model.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers[i](x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/scp_model.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39m# # add gene embedding\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/scp_model.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39m# if i % (len(self.layers) // self.num_adds)==0:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/scp_model.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m     \u001b[39m#     x = x + self.embed_gene\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/scp_model.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mtanh()\n",
      "File \u001b[0;32m~/.conda/envs/taeuk/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/taeuk/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/aiuser/taeuk/scp_model.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/scp_model.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m ,x):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/scp_model.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     x_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49melu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/scp_model.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39melu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x_)\u001b[39m+\u001b[39mx)\n",
      "File \u001b[0;32m~/.conda/envs/taeuk/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/taeuk/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/taeuk/lib/python3.10/site-packages/torch/nn/modules/activation.py:514\u001b[0m, in \u001b[0;36mELU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 514\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49melu(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malpha, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m~/.conda/envs/taeuk/lib/python3.10/site-packages/torch/nn/functional.py:1562\u001b[0m, in \u001b[0;36melu\u001b[0;34m(input, alpha, inplace)\u001b[0m\n\u001b[1;32m   1560\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39melu_(\u001b[39minput\u001b[39m, alpha)\n\u001b[1;32m   1561\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1562\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49melu(\u001b[39minput\u001b[39;49m, alpha)\n\u001b[1;32m   1563\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 7.82 GiB. GPU 0 has a total capacty of 23.64 GiB of which 7.73 GiB is free. Including non-PyTorch memory, this process has 15.90 GiB memory in use. Of the allocated memory 15.70 GiB is allocated by PyTorch, and 9.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# training & prediction\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "      \n",
    "train_size = 1.\n",
    "dim_model = 64\n",
    "num_layers = 1\n",
    "num_adds = 1 # 많이 더할수록(입력할수록) prediction이 유전자마다 비슷비슷해짐\n",
    "learning_rate = 0.04\n",
    "batch_size = 600\n",
    "num_epochs = 100 # 10 으로 했을때 0.65\n",
    "\n",
    "fix_random_seed(231111)\n",
    "model, mrrmse = train_model(device, train_size, dim_model, num_layers, num_adds,\n",
    "                            18211, \"Adam\", \"L1\", learning_rate, num_epochs, batch_size, True)\n",
    "pred = infer_model(device, model)\n",
    "data = pred.detach().cpu().numpy()\n",
    "df = pd.DataFrame(data).reset_index()\n",
    "df.columns = submission.columns\n",
    "display(df.head())\n",
    "\n",
    "gene_info = model.embed_gene.data.squeeze().cpu().numpy()\n",
    "gene_info = pd.DataFrame(gene_info)\n",
    "gene_info.index = submission.columns[1:]\n",
    "cell_info = model.embed_cell.weight.detach().cpu().numpy()\n",
    "cell_info = pd.DataFrame(cell_info)\n",
    "cell_info.index = [k for k in cell_type_dict.keys()]\n",
    "df_corr = cell_info.T.corr()\n",
    "df_corr.columns = [k for k in cell_type_dict.keys()]\n",
    "df_corr.index = [k for k in cell_type_dict.keys()]\n",
    "\n",
    "display(gene_info)\n",
    "display(cell_info)\n",
    "display(df_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "\n",
    "title = f\"scp_D{dim_model}_L{num_layers}_A{num_adds}_lr{learning_rate}_B{batch_size}_E{num_epochs}\"\n",
    "df.to_csv(\"/home/aiuser/taeuk/%s.csv\"%title, header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taeuk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
