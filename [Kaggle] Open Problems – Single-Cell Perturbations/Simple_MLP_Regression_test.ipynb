{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature select\n",
    "# feature는 cell_type, sm_name, mean value, SMILES 이용, \n",
    "# 최대한 id_map에 맞게 최소한으로 설정할건데 일단은 de_train을 기준으로 해보자\n",
    "\n",
    "de_train = pd.read_parquet(\"/home/aiuser/taeuk/open-problems-single-cell-perturbations/de_train.parquet\")\n",
    "id_map = pd.read_csv(\"/home/aiuser/taeuk/open-problems-single-cell-perturbations/id_map.csv\")\n",
    "submission = pd.read_csv(\"/home/aiuser/taeuk/open-problems-single-cell-perturbations/sample_submission.csv\")\n",
    "\n",
    "sm_name_id_map = sorted(id_map.sm_name.unique())\n",
    "cell_type_id_map = sorted(id_map.cell_type.unique())\n",
    "\n",
    "sm_name_de_train = sorted(de_train.sm_name.unique())\n",
    "cell_type_de_train = sorted(de_train.cell_type.unique())\n",
    "\n",
    "# cell type, compound dictionary \n",
    "\n",
    "cell_type_dict = {cell_type_de_train[i]:i for i in range(len(cell_type_de_train))}\n",
    "sm_name_dict = {sm_name_de_train[i]:i for i in range(len(sm_name_de_train))}\n",
    "\n",
    "# compound info by SMILES\n",
    "\n",
    "smiles = list(de_train.SMILES.unique())\n",
    "voc = []\n",
    "\n",
    "r = re.compile(\".\")\n",
    "for sm in smiles:\n",
    "    voc += list(set(r.findall(sm)))\n",
    "voc = list(set(voc))\n",
    "voc.sort()\n",
    "voc[:10]\n",
    "\n",
    "df_smile = pd.DataFrame(np.zeros((len(smiles), len(voc))).astype(int))\n",
    "df_smile.columns = voc\n",
    "for i in range(df_smile.shape[0]):\n",
    "    for ele in r.findall(smiles[i]):\n",
    "        df_smile[ele][i] += 1\n",
    "df_smile = pd.DataFrame(smiles).join(df_smile)\n",
    "df_smile.columns = [\"SMILES\"] + list(df_smile.columns[1:])\n",
    "sm_id = de_train.iloc[:, 1:4].drop(\"sm_lincs_id\", axis=1).drop_duplicates()\n",
    "df_smile = sm_id.merge(df_smile, how=\"left\", on=\"SMILES\")\n",
    "df_smile.drop(\"SMILES\", axis=1, inplace=True)\n",
    "\n",
    "# build dataloader\n",
    "\n",
    "class SCPset(Dataset):\n",
    "    def __init__(self, dataset, df_smile, cell_type_dict, sm_name_dict):\n",
    "        super(SCPset, self).__init__()\n",
    "        if dataset is None:\n",
    "            self.x = id_map.iloc[:, 1:]\n",
    "            self.y = None\n",
    "        else:\n",
    "            self.x = dataset.iloc[:, :2]\n",
    "            self.y = dataset.iloc[:, 5:]\n",
    "        self.smile = df_smile\n",
    "        self.cell_type_dict = cell_type_dict\n",
    "        self.sm_name_dict = sm_name_dict\n",
    "   \n",
    "    def __getitem__(self, idx):\n",
    "        cell, name = self.x.iloc[idx]\n",
    "        x_cell = self.cell_type_dict[cell]\n",
    "        x_comp = self.smile.loc[self.smile.sm_name==name, \"#\":].values[0]\n",
    "        ele_idx = np.where(x_comp!=0)[0][1:]\n",
    "        ele_val = x_comp[ele_idx]\n",
    "        ele_idx = list(ele_idx) + [0]*(20-len(ele_idx))\n",
    "        ele_val = list(ele_val) + [0]*(20-len(ele_val))\n",
    "        x = [x_cell] + list(ele_idx) + list(ele_val)\n",
    "        if self.y is None:\n",
    "            return torch.tensor(x, dtype=torch.int64)\n",
    "        else:\n",
    "            y = self.y.iloc[idx, :]\n",
    "            return torch.tensor(x, dtype=torch.int64),\\\n",
    "                    torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "'''\n",
    "input : [cell, comp, smil]\n",
    "x     : tensor size of (B, dim_embed)      \n",
    "'''\n",
    "        \n",
    "class SCPmodel(nn.Module):\n",
    "    def __init__(self, dim_embed, num_layers, num_adds, gene, device):\n",
    "        super(SCPmodel, self).__init__()\n",
    "        self.embed_cell = nn.Embedding(6, dim_embed//2, device=device)\n",
    "        self.embed_comp = nn.Embedding(33, dim_embed//2, padding_idx=0, device=device)\n",
    "        self.fc1 = nn.Linear(dim_embed, 256, device=device)\n",
    "        self.fc2 = nn.Linear(256, 18211, device=device)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "            \n",
    "    def forward(self, x):\n",
    "        cell = self.embed_cell(x[:, 0])\n",
    "        comp_idx = x[:, 1:21]\n",
    "        comp_val = x[:, 21:]\n",
    "        comp = self.embed_comp(comp_idx)\n",
    "        comp = comp * comp_val.unsqueeze(2)\n",
    "        comp = comp.mean(dim=1, keepdim=False)\n",
    "        x = torch.cat([cell, comp], dim=1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define util function\n",
    "\n",
    "def MRRMSE(pred, y):\n",
    "      pred = pred.detach().cpu().numpy()\n",
    "      y = y.detach().cpu().numpy()\n",
    "      return np.sqrt(np.square(y - pred).mean(axis=1)).mean()    \n",
    "\n",
    "def mrrmse_loss(pred, y):\n",
    "      return torch.sqrt(torch.square(pred - y).mean(dim=1)).mean()\n",
    "\n",
    "def compose_loss(pred, y):\n",
    "      return mrrmse_loss(pred, y) + F.smooth_l1_loss(pred, y)\n",
    "\n",
    "def fix_random_seed(seed):\n",
    "    #random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training function\n",
    "\n",
    "def train_model(device, train_size, dim_model, num_layers, num_adds, genes, optimizer, criterion, learning_rate, num_epochs, batch_size, verbose):\n",
    "      \n",
    "      train_idx = np.random.choice(de_train.shape[0], int(de_train.shape[0]*train_size), replace=False)\n",
    "      train_loader = DataLoader(SCPset(de_train.iloc[train_idx, :], df_smile, cell_type_dict, sm_name_dict),\n",
    "                                batch_size=batch_size, shuffle=True)\n",
    "      valid_loader = [1]\n",
    "      if train_size < 1.:\n",
    "            valid_idx = list(set(np.arange(de_train.shape[0])) - set(train_idx))\n",
    "            valid_loader = DataLoader(SCPset(de_train.iloc[valid_idx, :], df_smile, cell_type_dict, sm_name_dict),\n",
    "                                      batch_size=batch_size, shuffle=True)\n",
    "\n",
    "      model = SCPmodel(dim_model, num_layers, num_adds, genes, device)\n",
    "      \n",
    "      if optimizer.lower()==\"sgd\":\n",
    "            optimizer = SGD(list(model.parameters())+[model.embed_gene], lr=learning_rate, momentum=0.)\n",
    "      elif optimizer.lower()=='adam':\n",
    "            optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "      else:\n",
    "            print(\"Wrong optimizer!\")\n",
    "            return\n",
    "      \n",
    "      scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)\n",
    "      \n",
    "      if criterion.lower()==\"l1\":\n",
    "            criterion = nn.SmoothL1Loss(0.01)\n",
    "      elif criterion.lower()==\"l2\":\n",
    "            criterion = nn.MSELoss()\n",
    "      elif criterion.lower()==\"MRRMSE\":\n",
    "            criterion = mrrmse_loss\n",
    "      elif criterion.lower() == \"compose\":\n",
    "            criterion = compose_loss\n",
    "      else:\n",
    "            print(\"Wrong criterion!\")\n",
    "            return\n",
    "      \n",
    "      best_mrrmse = 10\n",
    "      for epoch in tqdm(range(1, num_epochs+1)):\n",
    "            train_loss = 0.\n",
    "            valid_loss = 0.\n",
    "            train_mrrmse = 0.\n",
    "            valid_mrrmse = 0.\n",
    "            \n",
    "            model.train()\n",
    "            for x, y in train_loader:\n",
    "                  x, y = x.to(device), y.to(device)\n",
    "                  optimizer.zero_grad()\n",
    "                  pred = model(x)\n",
    "                  if F.mse_loss(pred[0,:], pred[1,:]).item() < 0.0001:\n",
    "                        print(\"trivial solution !, mse of prediction is %.6f\"%F.mse_loss(pred[0,:], pred[1,:]).item())\n",
    "                  loss = criterion(pred, y)\n",
    "                  #model.embed_gene.retain_grad()\n",
    "                  loss.backward()\n",
    "                  optimizer.step()\n",
    "                  \n",
    "                  train_loss += loss.item()\n",
    "                  train_mrrmse += MRRMSE(pred, y)\n",
    "            if train_size < 1.:\n",
    "                  model.eval()\n",
    "                  for x, y in valid_loader:\n",
    "                        x, y = x.to(device), y.to(device)\n",
    "                        with torch.no_grad():\n",
    "                              pred = model(x)\n",
    "                              loss = criterion(pred, y)\n",
    "                        \n",
    "                        valid_loss += loss.item()\n",
    "                        valid_mrrmse += MRRMSE(pred, y)\n",
    "            scheduler.step()      \n",
    "            # print loss per epoch\n",
    "            if verbose:\n",
    "                  print(\"[Epoch : %2d] [Loss : %.4f / %.4f] [MRRMSE : %.3f / %.3f]\"%(\n",
    "                        epoch, train_loss/len(train_loader), valid_loss/len(valid_loader),\n",
    "                        train_mrrmse/len(train_loader), valid_mrrmse/len(valid_loader)))\n",
    "            if train_size < 1. and best_mrrmse > valid_mrrmse/len(valid_loader):\n",
    "                  best_mrrmse = valid_mrrmse/len(valid_loader)\n",
    "            \n",
    "      return model, best_mrrmse\n",
    "\n",
    "def infer_model(device, model):\n",
    "      test_loader = DataLoader(SCPset(None, df_smile, cell_type_dict, sm_name_dict),\n",
    "                               batch_size=255, shuffle=False)\n",
    "      model.eval()\n",
    "      for x in test_loader:\n",
    "            x = x.to(device)\n",
    "            with torch.no_grad():\n",
    "                  pred = model(x)\n",
    "      return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5421fb03a2384c06a594a603d3098f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1875206/2686368559.py:72: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  torch.tensor(y, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch :  1] [Loss : 0.5439 / 0.0000] [MRRMSE : 1.277 / 0.000]\n",
      "[Epoch :  2] [Loss : 0.5232 / 0.0000] [MRRMSE : 1.243 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000011\n",
      "[Epoch :  3] [Loss : 0.5294 / 0.0000] [MRRMSE : 1.254 / 0.000]\n",
      "[Epoch :  4] [Loss : 0.5323 / 0.0000] [MRRMSE : 1.252 / 0.000]\n",
      "[Epoch :  5] [Loss : 0.5517 / 0.0000] [MRRMSE : 1.293 / 0.000]\n",
      "[Epoch :  6] [Loss : 0.5188 / 0.0000] [MRRMSE : 1.239 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch :  7] [Loss : 0.5104 / 0.0000] [MRRMSE : 1.228 / 0.000]\n",
      "[Epoch :  8] [Loss : 0.5014 / 0.0000] [MRRMSE : 1.213 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000018\n",
      "[Epoch :  9] [Loss : 0.5026 / 0.0000] [MRRMSE : 1.214 / 0.000]\n",
      "[Epoch : 10] [Loss : 0.5179 / 0.0000] [MRRMSE : 1.230 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 11] [Loss : 0.5013 / 0.0000] [MRRMSE : 1.206 / 0.000]\n",
      "[Epoch : 12] [Loss : 0.5003 / 0.0000] [MRRMSE : 1.205 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 13] [Loss : 0.4797 / 0.0000] [MRRMSE : 1.180 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 14] [Loss : 0.4812 / 0.0000] [MRRMSE : 1.188 / 0.000]\n",
      "[Epoch : 15] [Loss : 0.4848 / 0.0000] [MRRMSE : 1.191 / 0.000]\n",
      "[Epoch : 16] [Loss : 0.4903 / 0.0000] [MRRMSE : 1.196 / 0.000]\n",
      "[Epoch : 17] [Loss : 0.4817 / 0.0000] [MRRMSE : 1.182 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 18] [Loss : 0.4766 / 0.0000] [MRRMSE : 1.176 / 0.000]\n",
      "[Epoch : 19] [Loss : 0.4676 / 0.0000] [MRRMSE : 1.164 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "trivial solution !, mse of prediction is 0.000008\n",
      "[Epoch : 20] [Loss : 0.4620 / 0.0000] [MRRMSE : 1.156 / 0.000]\n",
      "[Epoch : 21] [Loss : 0.4886 / 0.0000] [MRRMSE : 1.202 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 22] [Loss : 0.4999 / 0.0000] [MRRMSE : 1.214 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000019\n",
      "trivial solution !, mse of prediction is 0.000074\n",
      "[Epoch : 23] [Loss : 0.4810 / 0.0000] [MRRMSE : 1.181 / 0.000]\n",
      "[Epoch : 24] [Loss : 0.4629 / 0.0000] [MRRMSE : 1.161 / 0.000]\n",
      "[Epoch : 25] [Loss : 0.4724 / 0.0000] [MRRMSE : 1.177 / 0.000]\n",
      "[Epoch : 26] [Loss : 0.4662 / 0.0000] [MRRMSE : 1.168 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 27] [Loss : 0.4599 / 0.0000] [MRRMSE : 1.158 / 0.000]\n",
      "[Epoch : 28] [Loss : 0.4578 / 0.0000] [MRRMSE : 1.163 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 29] [Loss : 0.4844 / 0.0000] [MRRMSE : 1.189 / 0.000]\n",
      "[Epoch : 30] [Loss : 0.4557 / 0.0000] [MRRMSE : 1.151 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 31] [Loss : 0.4658 / 0.0000] [MRRMSE : 1.173 / 0.000]\n",
      "[Epoch : 32] [Loss : 0.4575 / 0.0000] [MRRMSE : 1.153 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 33] [Loss : 0.4501 / 0.0000] [MRRMSE : 1.147 / 0.000]\n",
      "[Epoch : 34] [Loss : 0.4488 / 0.0000] [MRRMSE : 1.144 / 0.000]\n",
      "[Epoch : 35] [Loss : 0.4472 / 0.0000] [MRRMSE : 1.141 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 36] [Loss : 0.4554 / 0.0000] [MRRMSE : 1.157 / 0.000]\n",
      "[Epoch : 37] [Loss : 0.4435 / 0.0000] [MRRMSE : 1.144 / 0.000]\n",
      "[Epoch : 38] [Loss : 0.4621 / 0.0000] [MRRMSE : 1.157 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 39] [Loss : 0.4656 / 0.0000] [MRRMSE : 1.166 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 40] [Loss : 0.4459 / 0.0000] [MRRMSE : 1.150 / 0.000]\n",
      "[Epoch : 41] [Loss : 0.4494 / 0.0000] [MRRMSE : 1.153 / 0.000]\n",
      "[Epoch : 42] [Loss : 0.4441 / 0.0000] [MRRMSE : 1.143 / 0.000]\n",
      "[Epoch : 43] [Loss : 0.4357 / 0.0000] [MRRMSE : 1.133 / 0.000]\n",
      "[Epoch : 44] [Loss : 0.4333 / 0.0000] [MRRMSE : 1.137 / 0.000]\n",
      "[Epoch : 45] [Loss : 0.4396 / 0.0000] [MRRMSE : 1.141 / 0.000]\n",
      "[Epoch : 46] [Loss : 0.4253 / 0.0000] [MRRMSE : 1.116 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 47] [Loss : 0.4256 / 0.0000] [MRRMSE : 1.121 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 48] [Loss : 0.4256 / 0.0000] [MRRMSE : 1.118 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 49] [Loss : 0.4200 / 0.0000] [MRRMSE : 1.109 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 50] [Loss : 0.4196 / 0.0000] [MRRMSE : 1.112 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 51] [Loss : 0.4329 / 0.0000] [MRRMSE : 1.134 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 52] [Loss : 0.4107 / 0.0000] [MRRMSE : 1.099 / 0.000]\n",
      "[Epoch : 53] [Loss : 0.4375 / 0.0000] [MRRMSE : 1.136 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000001\n",
      "[Epoch : 54] [Loss : 0.4135 / 0.0000] [MRRMSE : 1.101 / 0.000]\n",
      "[Epoch : 55] [Loss : 0.4062 / 0.0000] [MRRMSE : 1.093 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000024\n",
      "[Epoch : 56] [Loss : 0.4210 / 0.0000] [MRRMSE : 1.119 / 0.000]\n",
      "[Epoch : 57] [Loss : 0.4091 / 0.0000] [MRRMSE : 1.104 / 0.000]\n",
      "[Epoch : 58] [Loss : 0.4003 / 0.0000] [MRRMSE : 1.085 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 59] [Loss : 0.4089 / 0.0000] [MRRMSE : 1.095 / 0.000]\n",
      "[Epoch : 60] [Loss : 0.3968 / 0.0000] [MRRMSE : 1.082 / 0.000]\n",
      "[Epoch : 61] [Loss : 0.3934 / 0.0000] [MRRMSE : 1.079 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 62] [Loss : 0.3945 / 0.0000] [MRRMSE : 1.078 / 0.000]\n",
      "[Epoch : 63] [Loss : 0.3865 / 0.0000] [MRRMSE : 1.066 / 0.000]\n",
      "[Epoch : 64] [Loss : 0.3984 / 0.0000] [MRRMSE : 1.086 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000053\n",
      "[Epoch : 65] [Loss : 0.4091 / 0.0000] [MRRMSE : 1.111 / 0.000]\n",
      "[Epoch : 66] [Loss : 0.3949 / 0.0000] [MRRMSE : 1.082 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 67] [Loss : 0.3878 / 0.0000] [MRRMSE : 1.071 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 68] [Loss : 0.3841 / 0.0000] [MRRMSE : 1.066 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 69] [Loss : 0.3983 / 0.0000] [MRRMSE : 1.093 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 70] [Loss : 0.3863 / 0.0000] [MRRMSE : 1.074 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 71] [Loss : 0.3852 / 0.0000] [MRRMSE : 1.072 / 0.000]\n",
      "[Epoch : 72] [Loss : 0.3822 / 0.0000] [MRRMSE : 1.064 / 0.000]\n",
      "[Epoch : 73] [Loss : 0.3795 / 0.0000] [MRRMSE : 1.055 / 0.000]\n",
      "[Epoch : 74] [Loss : 0.3805 / 0.0000] [MRRMSE : 1.061 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 75] [Loss : 0.3813 / 0.0000] [MRRMSE : 1.060 / 0.000]\n",
      "[Epoch : 76] [Loss : 0.3745 / 0.0000] [MRRMSE : 1.049 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 77] [Loss : 0.3822 / 0.0000] [MRRMSE : 1.066 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 78] [Loss : 0.3715 / 0.0000] [MRRMSE : 1.046 / 0.000]\n",
      "[Epoch : 79] [Loss : 0.3936 / 0.0000] [MRRMSE : 1.085 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 80] [Loss : 0.3799 / 0.0000] [MRRMSE : 1.066 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 81] [Loss : 0.3780 / 0.0000] [MRRMSE : 1.064 / 0.000]\n",
      "[Epoch : 82] [Loss : 0.3705 / 0.0000] [MRRMSE : 1.046 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000030\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 83] [Loss : 0.3693 / 0.0000] [MRRMSE : 1.043 / 0.000]\n",
      "[Epoch : 84] [Loss : 0.3829 / 0.0000] [MRRMSE : 1.069 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 85] [Loss : 0.3764 / 0.0000] [MRRMSE : 1.063 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 86] [Loss : 0.3799 / 0.0000] [MRRMSE : 1.063 / 0.000]\n",
      "[Epoch : 87] [Loss : 0.3748 / 0.0000] [MRRMSE : 1.056 / 0.000]\n",
      "[Epoch : 88] [Loss : 0.3722 / 0.0000] [MRRMSE : 1.049 / 0.000]\n",
      "[Epoch : 89] [Loss : 0.3735 / 0.0000] [MRRMSE : 1.054 / 0.000]\n",
      "[Epoch : 90] [Loss : 0.3726 / 0.0000] [MRRMSE : 1.051 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 91] [Loss : 0.3784 / 0.0000] [MRRMSE : 1.062 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 92] [Loss : 0.3698 / 0.0000] [MRRMSE : 1.047 / 0.000]\n",
      "[Epoch : 93] [Loss : 0.3749 / 0.0000] [MRRMSE : 1.062 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000007\n",
      "[Epoch : 94] [Loss : 0.3702 / 0.0000] [MRRMSE : 1.048 / 0.000]\n",
      "[Epoch : 95] [Loss : 0.3758 / 0.0000] [MRRMSE : 1.060 / 0.000]\n",
      "[Epoch : 96] [Loss : 0.3729 / 0.0000] [MRRMSE : 1.053 / 0.000]\n",
      "[Epoch : 97] [Loss : 0.3712 / 0.0000] [MRRMSE : 1.048 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 98] [Loss : 0.3710 / 0.0000] [MRRMSE : 1.054 / 0.000]\n",
      "[Epoch : 99] [Loss : 0.3727 / 0.0000] [MRRMSE : 1.053 / 0.000]\n",
      "trivial solution !, mse of prediction is 0.000000\n",
      "[Epoch : 100] [Loss : 0.3697 / 0.0000] [MRRMSE : 1.046 / 0.000]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "SCPset.__init__() missing 1 required positional argument: 'sm_name_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/aiuser/taeuk/Simple_MLP_Regression_test.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/Simple_MLP_Regression_test.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m fix_random_seed(\u001b[39m231111\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/Simple_MLP_Regression_test.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m model, mrrmse \u001b[39m=\u001b[39m train_model(device, train_size, dim_model, num_layers, num_adds,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/Simple_MLP_Regression_test.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m                             \u001b[39m18211\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mAdam\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mL1\u001b[39m\u001b[39m\"\u001b[39m, learning_rate, num_epochs, batch_size, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/Simple_MLP_Regression_test.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m pred \u001b[39m=\u001b[39m infer_model(device, model)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/Simple_MLP_Regression_test.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m data \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/Simple_MLP_Regression_test.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data)\u001b[39m.\u001b[39mreset_index()\n",
      "\u001b[1;32m/home/aiuser/taeuk/Simple_MLP_Regression_test.ipynb Cell 6\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/Simple_MLP_Regression_test.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=79'>80</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minfer_model\u001b[39m(device, model):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/Simple_MLP_Regression_test.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=80'>81</a>\u001b[0m       test_loader \u001b[39m=\u001b[39m DataLoader(SCPset(\u001b[39mNone\u001b[39;49;00m, cell_type_dict, sm_name_dict),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/Simple_MLP_Regression_test.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=81'>82</a>\u001b[0m                                batch_size\u001b[39m=\u001b[39m\u001b[39m255\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/Simple_MLP_Regression_test.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=82'>83</a>\u001b[0m       model\u001b[39m.\u001b[39meval()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiuser/home/aiuser/taeuk/Simple_MLP_Regression_test.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m test_loader:\n",
      "\u001b[0;31mTypeError\u001b[0m: SCPset.__init__() missing 1 required positional argument: 'sm_name_dict'"
     ]
    }
   ],
   "source": [
    "# training & prediction\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "      \n",
    "train_size = 1.\n",
    "dim_model = 128\n",
    "num_layers = 1\n",
    "num_adds = 1 # 많이 더할수록(입력할수록) prediction이 유전자마다 비슷비슷해짐\n",
    "learning_rate = 0.015\n",
    "batch_size = 64\n",
    "num_epochs = 100 # 10 으로 했을때 0.65\n",
    "\n",
    "fix_random_seed(231111)\n",
    "model, mrrmse = train_model(device, train_size, dim_model, num_layers, num_adds,\n",
    "                            18211, \"Adam\", \"L1\", learning_rate, num_epochs, batch_size, True)\n",
    "pred = infer_model(device, model)\n",
    "data = pred.detach().cpu().numpy()\n",
    "df = pd.DataFrame(data).reset_index()\n",
    "df.columns = submission.columns\n",
    "display(df.head())\n",
    "\n",
    "gene_info = model.embed_gene.data.squeeze().cpu().numpy()\n",
    "gene_info = pd.DataFrame(gene_info)\n",
    "gene_info.index = submission.columns[1:]\n",
    "cell_info = model.embed_cell.weight.detach().cpu().numpy()\n",
    "cell_info = pd.DataFrame(cell_info)\n",
    "cell_info.index = [k for k in cell_type_dict.keys()]\n",
    "df_corr = cell_info.T.corr()\n",
    "df_corr.columns = [k for k in cell_type_dict.keys()]\n",
    "df_corr.index = [k for k in cell_type_dict.keys()]\n",
    "\n",
    "display(gene_info)\n",
    "display(cell_info)\n",
    "display(df_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "\n",
    "title = f\"scp_D{dim_model}_L{num_layers}_A{num_adds}_lr{learning_rate}_B{batch_size}_E{num_epochs}\"\n",
    "df.to_csv(\"/home/aiuser/taeuk/%s.csv\"%title, header=True, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taeuk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
